# migrating a production couchdb database with joyent and stud

## tl;dr

step by step how to install [couchdb](http://couchdb.apache.org) in ubuntu. but really, you should use [iriscouch](http://iriscouch.com) for your production couchdb needs. if you need help don’t forget to go to #couchdb on irc.freenode.org, these guys are incredibly helpful

if you love node.js don’t forget to give [nodejitsu](http://nodejitsu.com) a try too!

## intro

this week i had to migrate my first production database to a new environment. this documents the process in the hope that others find it useful

in my case i was updating a old couchdb mostly for two reasons:

* this particular version of couchdb had a bug in handling ssl
* couchdb versions prior to 1.2.0 didn't automatically resume replication after restart or auto compaction

in this tutorial you will find information on how to upgrade your couchdb, keep production running and safely “switch needles” after your new environment is tested and in production

## node.js

in this tutorial i’m going to use a lot of node.js tools. if you don’t have it installed you can do:

```
mkdir /opt/install
cd /opt/install
wget http://nodejs.org/dist/node-latest.tar.gz
tar xvf node-latest.tar.gz 
cd node-v*/
./configure 
make
make install
#
# Install some cool tools i use all the time
# and might be referenced in this article
#
npm install -g jsontool nave ghcopy nd futon cdir
```

## joyent

i’m a big fan of [joyent](http://joyent.com) so decided to use them in this tutorial. however i decided not to use [smartos](http://smartos.org/) since at the time of this writting the support for openssl 1.0.1 does not exist

to use joyent you first need to download and install the `smartdc` client from npm:

```
npm install -g smartdc
sdc-setup
```

this should have installed `smartdc` and configured it with your help. however if you need some more pointers please refer to the [official smartdc documentation](https://github.com/joyent/node-smartdc)

if you are also intending to create a hot standby replica of your production system you will want to follow these steps but place them in different data centers. you can see the list of available data centers by doing:

```
sdc-listdatacenters \
  -u https://us-east-1.api.joyentcloud.com \
  -a username \
  -k keyname
```

this assumes your username is `username` and you wish to authenticate using the key information you store in joyent at set up time as `keyname`

here is what the response to this request currently looks like:

``` javascript
{
  "us-east-1": "https://us-east-1.api.joyentcloud.com",
  "us-west-1": "https://us-west-1.api.joyentcloud.com",
  "us-sw-1": "https://us-sw-1.api.joyentcloud.com",
  "eu-ams-1": "https://eu-ams-1.api.joyentcloud.com"
}
```

in this tutorial i’m going to use the https://us-east-1.api.joyentcloud.com data center for the production couchdb and https://eu-ams-1.api.joyentcloud.com for the hot standby replica

we now need to select the operative system we are going to install as well as the size of our virtual machine. in joyent they call the available bundled virtual machine images `dataset` and the virtual machine sizes as `packages`. if you are curious about what other do, you can check the documentation of [pkgcloud](https://github.com/nodejitsu/pkgcloud) for a unified vocabulary

```
sdc-listdatasets \
  -u https://us-east-1.api.joyentcloud.com \
  -a username \
  -k keyname \
  | json -a urn \
  | grep ubuntu
```

we are going to use the latest ubuntu, a.k.a. `sdc:jpc:ubuntu-12.04:2.3.1`

* sdc:sdc:ubuntu-10.04:1.0.1
* sdc:jpc:ubuntu-12.04-enstratus-public:2.0.2
* sdc:jpc:ubuntu-12.04:2.1.2
* sdc:admin:ubuntu-10.04-enstratus-public:1.0.1
* sdc:jpc:ubuntu-12.04:2.2.1
* **sdc:jpc:ubuntu-12.04:2.3.1**

now to select the size of our virtual machine:

```
sdc-listpackages \
  -u https://us-east-1.api.joyentcloud.com \
  -a username \
  -k keyname \
  | json -a name
```

here is the list as of today. to understand this fully check more details at the [joyent website](http://joyent.com/products/joyent-cloud/pricing)

* extra small 512 mb
* **small 1gb**
* medium 2gb
* medium 4gb
* **large 8gb**
* large 16gb
* xxl 48gb
* xl 32gb

depending on how big your databases are you should select a different image. unfortunately it seems like in joyent disk space is coupled with memory and number of vcpus, which is not great for couchdb. feel free to reach out to them as ask them why (or for a custom build with more disk space)

in this tutorial i’m picking the **medium 2gb** for the hot standby replica, an a **large 8gb** for the live system

now you can create your live couchdb:

```
sdc-createmachine \
  -u https://us-east-1.api.joyentcloud.com \
  -a username \
  -k keyname \
  --name couch-joyent-0 \
  --dataset sdc:jpc:ubuntu-12.04:2.3.1 \
  --package "Large 8GB"
```

this will output server details. make sure you log these somewhere

now create the replica

```
sdc-createmachine \
  -u https://eu-ams-1.api.joyentcloud.com \
  -a username \
  -k keyname \
  --name couch-joyent-1 \
  --dataset sdc:jpc:ubuntu-12.04:2.3.1 \
  --package "Medium 2GB"
```

## ubuntu

let’s start by connecting to our virtual machines. i would recommend [iterm2](http://www.iterm2.com) so you can browse between local, live and replica. 

```
ssh root@165.255.222.111
ssh root@37.255.222.112
```

i would also change your `ps1` so you can easily distinguish between the two machines:

```
vi ~/.bashrc
# Edit the PS1 lines and replace with something like:
# Live:
# PS1='${debian_chroot:+($debian_chroot)}\u@couch-live-us:\w\$ '
# Replica:
# PS1='${debian_chroot:+($debian_chroot)}\u@couch-replica-eu:\w\$ '
. ~/.bashrc
```

some ubuntu machines don’t ship with `git` and `make`, so let’s upgrade all our packages and install these two:

```
apt-get update
apt-get upgrade
apt-get install git make gcc build-essential -y
```

these machines might not have node.js, so follow the steps you did before to install

## couchdb

i would recommend you follow the couchdb wiki on [installing couchdb on ubuntu](http://wiki.apache.org/couchdb/Installing_on_Ubuntu).

however i’m going to document here the exact steps i took

```
mkdir /opt/install
cd /opt/install
# make sure you update this if a new version is out
wget http://mirrors.fe.up.pt/pub/apache/couchdb/releases/1.2.0/apache-couchdb-1.2.0.tar.gz
apt-get install -y erlang-dev erlang-manpages erlang-base-hipe erlang-eunit erlang-nox erlang-xmerl erlang-inets libmozjs185-dev libicu-dev libcurl4-gnutls-dev libtool
tar xvzf apache-couchdb-1.2.0.tar.gz
cd apache-couchdb-*
./configure
make
make install
```

couchdb is now built but we still need to create a user for couch to use, and set appropriate permissions and ownership

```
useradd -d /var/lib/couchdb couchdb
chown -R couchdb: /usr/local/var/{lib,log,run}/couchdb /usr/local/etc/couchdb
chmod 0770 /usr/local/var/{lib,log,run}/couchdb/
chmod 664 /usr/local/etc/couchdb/*.ini
chmod 775 /usr/local/etc/couchdb/*.d
```

finally we want to set up `init.d` scripts so we can daemonize couchdb and manage it’s service like all other ubuntu processes

```
# In case Ubuntu has some trash from default instalation
rm /etc/logrotate.d/couchdb /etc/init.d/couchdb
ln -s /usr/local/etc/logrotate.d/couchdb /etc/logrotate.d/couchdb
ln -s /usr/local/etc/init.d/couchdb  /etc/init.d/couchdb
update-rc.d couchdb defaults
```

let’s checkpoint here and make sure everything worked:

```
service couchdb start
curl localhost:5984
service couchdb stop
```

if something failed, it’s likely you will want to kill couchdb processes you left lying around. you can execute this command to crash all things related to couchdb `ps -u couchdb -o pid= | xargs kill -9`

ok, let’s put our couchdb running:

```
service couchdb start
```

## stud

[stud](https://github.com/bumptech/stud) stands for the scalable tls unwrapping daemon, and it’s a great ssl terminator that works on top of libev and openssl

i decided not to expose couchdb via regular http. as for https `stud` will be our front end to couchdb.

installing `stud` in ubuntu is incredibly simple:

```
apt-get install libev4 libssl-dev libev-dev -y
cd /opt/install
git clone git://github.com/bumptech/stud.git
cd stud
make
make install
```

stud doesn’t come bundled with all the nice things couchdb does, so we need to create similar artifacts:

```
mkdir /var/run/stud
mkdir /usr/local/var/run/stud
mkdir /usr/local/etc/stud
touch /usr/local/etc/stud/stud.conf
```

you will also need a valid certificate for the domain you wish to use to expose your couchdb database. get the [pemfile](http://en.wikipedia.org/wiki/Privacy_Enhanced_Mail) and place it in `/usr/local/etc/stud/stud.pem`. a `pemfile` will include a private key and certificate information

```
touch /usr/local/etc/stud/stud.pem
vi /usr/local/etc/stud/stud.pem
```

let’s make sure we handle security properly:

```
useradd -d /var/lib/_stud _stud
chown _stud: /usr/local/etc/stud/stud.pem
chown _stud: /var/run/stud
chown -R _stud: /usr/local/var/run/stud /usr/local/etc/stud
chmod 0770 /usr/local/var/run/stud/
chmod 664 /usr/local/etc/stud/*.conf
chmod 600 /usr/local/etc/stud/stud.pem
mkdir /etc/stud
touch /etc/stud/stud.conf
```

ubuntu has a init.d script for `stud`. however i had to tweak it a bit to make it work with a custom installation, namely because it checked for the daemon before allowing be to changed the configuration.

you can download the init.d script from this [gist](https://gist.github.com/raw/4470972/stud)

```
rm /etc/init.d/stud
curl https://gist.github.com/dscape/4470972/raw/stud > /etc/init.d/stud
chmod +x /etc/init.d/stud
```

we installed `stud` from source and we need to provide the script the paths of our custom installation:

```
mkdir /etc/default/stud
vi /etc/default/stud
```

in my case these where the changes i needed to make:

```
PATH=/usr/local/bin:/sbin:/usr/sbin:/bin:/usr/bin
DAEMON=/usr/local/bin/stud 
CHROOT="/usr/local/var/run/stud"
COMMON_OPTIONS="-r $CHROOT -u $USER --config /usr/local/etc/stud/stud.conf"
```

final step is to put our stud configuration in `/usr/local/etc/stud/stud.conf`

```
frontend="[*]:6984"
backend="[127.0.0.1]:5984"
pem-file="/usr/local/etc/stud/stud.pem"
ssl=on
workers=2
syslog=on
```

Start stud:

```
update-rc.d stud defaults
service stud start
```

we can test this is working. go to your local machine and try it out:

```
$  curl 165.255.222.111:5984
curl: (7) couldn't connect to host
# -k means ignore ssl errors, cause the certificate is for a domain not ip
$  curl https://165.255.222.111:6984 -k
{"couchdb":"Welcome","version":"1.2.0"}
```

you should do the same check for the replica database `37.255.222.112`

now go to your dns provider and make sure you point something like` my-ouch.mydomain.com` to the ip of the machine (`a` record). do the same for your replica database. if you try to do curl against the domain you will see it now works with the `-k` option

an unsolicited advice: use multiple dns providers case one of them goes down. it happened once, might happen again

## configuring couchdb

we now need to configure our couchdb server. by default it comes in admin party mode but normally we want couchdb to be accessible only with a valid username and password

browse to your futon:

* https://my-couch.mydomain.com:6984/_utils/

and click on `fix this` to create our admin username and password

this will create an admin user but futon will still be visible in a read only capacity without authentication. to force authentication you should edit the `local.ini` file:

```
vi /usr/local/etc/couchdb/local.ini
```

add 

```
[couch_httpd_auth]
# some lines before
require_valid_user = true
```

this will work on server restart, but since we are editing this file let's add our auto-compaction configuration. compaction is a cpu/disk intensive operation so should be scheduled accordingly. the auto-compaction feature was introduced in couchdb 1.2.0. in here we are going to use a simple configuration, but i strongly advise you to check the [documentation](http://wiki.apache.org/couchdb/Compaction#Automatic_Compaction) instead of blindly copying

```
[daemons]
compaction_daemon={couch_compaction_daemon, start_link, []}

[compaction_daemon]
check_interval = 300
min_file_size = 131072

[compactions]
_default = [{db_fragmentation, "70%"}, {view_fragmentation, "60%"}, {from, "00:00"}, {to, "04:00"}, {strict_window, true}]
```

having worked in previous databases that do compactions, i would advise you to have at least 2 cpu's per database and do compactions when the writes in your database are only a few

now restart couchdb:

```
service couchdb stop
service couchdb start
```

ok, browse back to futon and see that it now requires username and password to access

## migrating the data

we now need to migrate our data from our production couchdb to our new live system. for this we will set a replicator job that will continuously replicate from the active production couch

you don't want to use futon for this, because continuous replications get cancelled on restart when done from futon. to do this right you need to use the `_replicator` database which was [introduced in couchdb 1.2.0](http://wiki.apache.org/couchdb/Replication).

just do this for each production database you want to continuously replicate.

```
function register_replication() {
  # $1 is database name
  # $2 is https://localuser:localpass@localhost:6984
  # $3 is https://remoteuser:remotepass@remote:6984
  DATA='{"source": "'$3'/'$1'","target": "'$1'","connection_timeout": 60000,"retries_per_request": 20,"http_connections": 30, "continuous":true, "user_ctx": { "roles": [ "_admin" ] }}'
  echo "database: "$1
  echo "local: "$2
  echo "remote: "$3
  echo "data: "$DATA
  echo
  echo "proceed? (control+c to cancel)"
  read
  curl -k -vX PUT $2/$1
  curl \
    -X POST \
    -k \
    -H "Content-type: application/json" \
    $2/_replicator \
    --data "$DATA"
}
```

you can now call this for each of the databases you want to replicate

```
register_replication \
  foobar \
  https://u1:pw2@localhost:6984 \
  https://u2:pw2@my-couch.mydomain.com:6984
```

and for your replica:

```
register_replication \
  foobar \
  https://u3:pw3@my-couch-replica.mydomain.com:6984
  https://u1:pw2@localhost:6984 \
```

## pulling the switch

when we decide to migrate to the new couch we can change the pointer to the new database and the old one will stop getting documents. after that we can remove the replications from the new live system. as for our replica, will will pull from our new live system and will be in standby mode always

you will need to change your configuration files so the correct server gets called. however, before doing that it is advisable that you start up your views. in couchdb are only first created on the first request. this means that if you migrate your system and you have a lot of traffic the first couple of requests will probably timeout, which is not that great

we need to connect to both the live and replica servers and make sure all views are created. (sidenote: if you are also adding new stuff to design documents [don't forget to do it right](http://wiki.apache.org/couchdb/How_to_deploy_view_changes_in_a_live_environment) or have exactly the same problem as described above)

You can now build the couchdb views by using the `couchdb-build-views` [script](https://github.com/dscape/frameless/blob/master/usage/couchdb-build-views):

```
npm install -g couchdb-build-views
couchdb-build-views --help
```

now just call the script:

```
couchdb-build-views --couch https://u3:pw3@my-couch-replica.mydomain.com:6984
couchdb-build-views --couch https://u2:pw2@my-couch.mydomain.com:6984
```

now that you are done, don't forget to delete that silly directory and clean your history:

```
cd
rm -rf ~/deletemelater/
rm ~/.bash_history 
history -c
touch ~/.bash_history
```

we are all done and ready for a new adventure: test this new environment in terms of load, and api. so don't forget to check the [couchdb changelog](http://wiki.apache.org/couchdb/Breaking_changes) and test appropriately before switching

